{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "La commande ci-dessous installe notre code dans l'environnement python de Colab en le clonant à partir de GitHub."
      ],
      "metadata": {
        "id": "2DUCXkIMXsnB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYC5J2g4OhJm",
        "outputId": "fdfd4a15-03fc-4acd-d112-e8e3c3192469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: yawbcc 0.1.0\n",
            "Uninstalling yawbcc-0.1.0:\n",
            "  Successfully uninstalled yawbcc-0.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/corralien/yawbcc.git\n",
            "  Cloning https://github.com/corralien/yawbcc.git to /tmp/pip-req-build-j4ir55x4\n",
            "  Running command git clone -q https://github.com/corralien/yawbcc.git /tmp/pip-req-build-j4ir55x4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: yawbcc\n",
            "  Building wheel for yawbcc (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yawbcc: filename=yawbcc-0.1.0-py3-none-any.whl size=6019 sha256=a8ed656189ce3be32304d3195eba9a38fc867cc6c44abaf8dbcba7ae828afd06\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1wq5muqd/wheels/3a/21/90/7da3f4fa36252d75b866614ee15de27ec23f4a14eed4e416d4\n",
            "Successfully built yawbcc\n",
            "Installing collected packages: yawbcc\n",
            "Successfully installed yawbcc-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y yawbcc\n",
        "!pip install git+https://github.com/corralien/yawbcc.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une fois que le package est installé, il est possible d'accéder aux modules et à leurs fonctions."
      ],
      "metadata": {
        "id": "V9PZmr7bYFOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from yawbcc.datasets import load_barcelona_wbc\n",
        "meta = load_barcelona_wbc()\n",
        "meta.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "69xHKCCrT3PT",
        "outputId": "22dbc9fd-ec54-405c-c620-810585b3621e"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            image         group label  width  height  \\\n",
              "0   ERB_77605.jpg  ERYTHROBLAST   ERB    360     363   \n",
              "1  ERB_202430.jpg  ERYTHROBLAST   ERB    360     363   \n",
              "2  ERB_677279.jpg  ERYTHROBLAST   ERB    360     363   \n",
              "3  ERB_655545.jpg  ERYTHROBLAST   ERB    360     363   \n",
              "4  ERB_560252.jpg  ERYTHROBLAST   ERB    360     363   \n",
              "\n",
              "                                                path  \n",
              "0  /root/yawbcc_data/barcelona/erythroblast/ERB_7...  \n",
              "1  /root/yawbcc_data/barcelona/erythroblast/ERB_2...  \n",
              "2  /root/yawbcc_data/barcelona/erythroblast/ERB_6...  \n",
              "3  /root/yawbcc_data/barcelona/erythroblast/ERB_6...  \n",
              "4  /root/yawbcc_data/barcelona/erythroblast/ERB_5...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d06d7c4a-57ab-4e78-af18-35dcf0de581a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>group</th>\n",
              "      <th>label</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ERB_77605.jpg</td>\n",
              "      <td>ERYTHROBLAST</td>\n",
              "      <td>ERB</td>\n",
              "      <td>360</td>\n",
              "      <td>363</td>\n",
              "      <td>/root/yawbcc_data/barcelona/erythroblast/ERB_7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ERB_202430.jpg</td>\n",
              "      <td>ERYTHROBLAST</td>\n",
              "      <td>ERB</td>\n",
              "      <td>360</td>\n",
              "      <td>363</td>\n",
              "      <td>/root/yawbcc_data/barcelona/erythroblast/ERB_2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ERB_677279.jpg</td>\n",
              "      <td>ERYTHROBLAST</td>\n",
              "      <td>ERB</td>\n",
              "      <td>360</td>\n",
              "      <td>363</td>\n",
              "      <td>/root/yawbcc_data/barcelona/erythroblast/ERB_6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ERB_655545.jpg</td>\n",
              "      <td>ERYTHROBLAST</td>\n",
              "      <td>ERB</td>\n",
              "      <td>360</td>\n",
              "      <td>363</td>\n",
              "      <td>/root/yawbcc_data/barcelona/erythroblast/ERB_6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ERB_560252.jpg</td>\n",
              "      <td>ERYTHROBLAST</td>\n",
              "      <td>ERB</td>\n",
              "      <td>360</td>\n",
              "      <td>363</td>\n",
              "      <td>/root/yawbcc_data/barcelona/erythroblast/ERB_5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d06d7c4a-57ab-4e78-af18-35dcf0de581a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d06d7c4a-57ab-4e78-af18-35dcf0de581a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d06d7c4a-57ab-4e78-af18-35dcf0de581a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "DATA_DIR = pathlib.Path.home() / 'yawbcc_data'\n",
        "\n",
        "train_ds = image_dataset_from_directory(DATA_DIR / 'barcelona', validation_split=0.2, subset='training', seed=2022,\n",
        "                                        image_size=(28, 28), batch_size=128, crop_to_aspect_ratio=True)\n",
        "\n",
        "valid_ds = image_dataset_from_directory(DATA_DIR / 'barcelona', validation_split=0.2, subset='validation', seed=2022,\n",
        "                                        image_size=(28, 28), batch_size=128, crop_to_aspect_ratio=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X-3BYCH4cFf",
        "outputId": "bfe417f1-2440-43b8-f083-b990096b9ea7"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17092 files belonging to 8 classes.\n",
            "Using 13674 files for training.\n",
            "Found 17092 files belonging to 8 classes.\n",
            "Using 3418 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Séparer variables explicatives / variable cible\n",
        "\n",
        "X = meta.drop(\"group\", axis = 1)\n",
        "\n",
        "Y = meta['group']"
      ],
      "metadata": {
        "id": "PlYQ0_AvbeuA"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and testing split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=42) "
      ],
      "metadata": {
        "id": "fa1WiJb2be_I"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EOLd0izUbfGf"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture du modèle LeNet\n",
        "# Instanciation du modèle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Activation, MaxPool2D\n",
        "\n",
        "lenet = Sequential()\n",
        "\n",
        "lenet.add(Conv2D(filters = 25,                   # Nombre de filtres\n",
        "                kernel_size = (1, 1),            # Dimensions du noyau\n",
        "                padding = 'valid',               # Mode de Dépassement\n",
        "                input_shape = (28, 28, 3),       # Dimensions de l'image en entrée\n",
        "                activation = 'relu'))         # Fonction d'activation\n",
        "          \n",
        "lenet.add(MaxPool2D(strides=2))\n",
        "\n",
        "lenet.add(Dense(units = 100,\n",
        "                activation = 'relu'))\n",
        "\n",
        "lenet.add(Conv2D(filters=30,kernel_size=(1,1),activation=\"sigmoid\",\n",
        "                padding=\"valid\"))\n",
        "\n",
        "\n",
        "lenet.add(MaxPool2D(strides=2))\n",
        "\n",
        "lenet.add(Flatten())\n",
        "\n",
        "lenet.add(Dense(units = 30,\n",
        "                activation = 'relu'))\n",
        "\n",
        "lenet.add(Dense(units = 55,\n",
        "                activation = 'softmax'))"
      ],
      "metadata": {
        "id": "D-CsOCIcHyUm"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwPzcyeDTd0f",
        "outputId": "1f89a9b3-386a-41fc-da5e-3ef08dcdbd9c"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_96 (Conv2D)          (None, 28, 28, 25)        100       \n",
            "                                                                 \n",
            " max_pooling2d_93 (MaxPoolin  (None, 14, 14, 25)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 14, 14, 100)       2600      \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 14, 14, 30)        3030      \n",
            "                                                                 \n",
            " max_pooling2d_94 (MaxPoolin  (None, 7, 7, 30)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_46 (Flatten)        (None, 1470)              0         \n",
            "                                                                 \n",
            " dense_120 (Dense)           (None, 30)                44130     \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 55)                1705      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,565\n",
            "Trainable params: 51,565\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lenet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "RuFI9v2nHN_1"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Vu que l'objectif du projet est de prédire l'identification et le classement de différents types de cellules sanguines normales en 8 classes, nous devrions axer nos recherches de métriques dans la catégorie des labels de classe.\n",
        "Suite à la prédominance d'une classe dans notre dataset, il serait peut être judicieux de privilégier comme métrique de seuil, la matrice de confusion et la mesure du F score (F1 Score, F0,5 Score ou F2 Score à déterminer par la suite), pour quantifier les erreurs de prédiction de classification.\n",
        "\n",
        "En terme de métriques de classement pour une classification déséquilibrée dans notre dataset, nous pouvons partir sur une analyse des caractéristiques de fonctionnement du récepteur (courbe ROC/analyse ROC) et AUC).\n",
        "Ces métriques de classement concernent davantage l'évaluation des classificateurs en fonction de leur efficacité à séparer les classes.\n",
        "Elles nécessitent qu'un classifieur prédise un score ou une probabilité d'appartenance à une classe.\n",
        "A partir de ce score, différents seuils peuvent être appliqués pour tester l'efficacité des classificateurs. Les modèles qui maintiennent un bon score sur une gamme de seuils auront une bonne séparation des classes et seront mieux classés.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "N2POYHawT744",
        "outputId": "da6af559-6755-4b07-c7c8-e96bfd18b2c5"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nVu que l'objectif du projet est de prédire l'identification et le classement de différents types de cellules sanguines normales en 8 classes, nous devrions axer nos recherches de métriques dans la catégorie des labels de classe.\\nSuite à la prédominance d'une classe dans notre dataset, il serait peut être judicieux de privilégier comme métrique de seuil, la matrice de confusion et la mesure du F score (F1 Score, F0,5 Score ou F2 Score à déterminer par la suite), pour quantifier les erreurs de prédiction de classification.\\n\\nEn terme de métriques de classement pour une classification déséquilibrée dans notre dataset, nous pouvons partir sur une analyse des caractéristiques de fonctionnement du récepteur (courbe ROC/analyse ROC) et AUC).\\nCes métriques de classement concernent davantage l'évaluation des classificateurs en fonction de leur efficacité à séparer les classes.\\nElles nécessitent qu'un classifieur prédise un score ou une probabilité d'appartenance à une classe.\\nA partir de ce score, différents seuils peuvent être appliqués pour tester l'efficacité des classificateurs. Les modèles qui maintiennent un bon score sur une gamme de seuils auront une bonne séparation des classes et seront mieux classés.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiler le modèle\n",
        "lenet.compile(loss='SparseCategoricalCrossentropy',   # fonction de perte pour la classification multiple\n",
        "              optimizer='adam',                       # algorithme d'optimisation (algorithme de descente de gradient)\n",
        "              metrics=['accuracy'])                   # métrique d'évaluation"
      ],
      "metadata": {
        "id": "o8jCx819T_Z_"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrainement du modèle LeNet\n",
        "\n",
        "training_history_lenet = lenet.fit_generator(\n",
        "            train_ds,                        \n",
        "            steps_per_epoch=20,\n",
        "            validation_data = valid_ds,        \n",
        "            epochs = 20,                           \n",
        "            verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqzZxMpf65Um",
        "outputId": "d9f5ac85-4e6c-408d-99f2-194b03174d4f"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 13s 567ms/step - loss: 2.8667 - accuracy: 0.1859 - val_loss: 2.4030 - val_accuracy: 0.1662\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 6s 307ms/step - loss: 2.1795 - accuracy: 0.1949 - val_loss: 1.9830 - val_accuracy: 0.2621\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 6s 311ms/step - loss: 1.9421 - accuracy: 0.2781 - val_loss: 1.9156 - val_accuracy: 0.2042\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 6s 317ms/step - loss: 1.8776 - accuracy: 0.3469 - val_loss: 1.8065 - val_accuracy: 0.3970\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 6s 304ms/step - loss: 1.7809 - accuracy: 0.4484 - val_loss: 1.7225 - val_accuracy: 0.4236\n",
            "Epoch 6/20\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.6871 - accuracy: 0.4688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 400 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 3s 181ms/step - loss: 1.7140 - accuracy: 0.4325 - val_loss: 1.6908 - val_accuracy: 0.4731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# évaluation performance du modèle : extraire de training_history_lenet les précisions sur les bases d'entraînement et de test obtenues pendant l'entraînement\n",
        "\n",
        "train_acc_lenet = training_history_lenet.history['accuracy']\n",
        "val_acc_lenet = training_history_lenet.history['val_accuracy']"
      ],
      "metadata": {
        "id": "znP71PnlWlDM"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prédire les classes de l'échantillon X_test à l'aide de la méthode predict du modèle LeNet. Stocker le résultat dans un tableau nommé test_pred_lenet.\n",
        "# Appliquer la méthode argmax sur les tableaux test_pred_lenet et y_test pour obtenir des vecteurs d'entiers correspondant aux classes prédites et réelles. Il faudra passer l'argument 'axis = 1' pour que l'argmax soit calculée sur les colonnes et non les lignes. Stocker les sorties des appels de la méthode argmax dans des tableaux nommés test_pred_lenet_class et y_test_class.\n",
        "\n",
        "test_pred_lenet = lenet.predict(X_test)\n",
        "\n",
        "test_pred_lenet_class = test_pred_lenet.argmax(axis = 1)\n",
        "\n",
        "y_test_class = Y_test.argmax(axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "pJVvwMRuWlU8",
        "outputId": "532b649c-9fd8-4735-defe-f3ecd9b7f13f"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-195-b8ae11f3b77f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Appliquer la méthode argmax sur les tableaux test_pred_lenet et y_test pour obtenir des vecteurs d'entiers correspondant aux classes prédites et réelles. Il faudra passer l'argument 'axis = 1' pour que l'argmax soit calculée sur les colonnes et non les lignes. Stocker les sorties des appels de la méthode argmax dans des tableaux nommés test_pred_lenet_class et y_test_class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_pred_lenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_pred_lenet_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pred_lenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calcul et affichage de la matrice de confusion\n",
        "matrice_confusion = confusion_matrix(Y_test, test_pred_lenet)\n",
        "print(\"Matrice de Confusion:\\n\",  matrice_confusion)\n",
        "\n",
        "print(\"\\nLe modèle LeNet a fait\", matrice_confusion[0, 1], \"Faux Positifs.\")\n",
        "\n",
        "# Calcul de l'accuracy, precision et rappel\n",
        "(VN, FP), (FN, VP) = confusion_matrix(Y_test, test_pred_lenet)\n",
        "n = len(y_test)\n",
        "\n",
        "print(\"\\nLenet Accuracy:\", (VP + VN) / n)\n",
        "\n",
        "print(\"\\nLenet Précision:\", VP / (VP + FP))\n",
        "\n",
        "print(\"\\nLenet Rappel:\", VP / (VP + FN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "_O5HJBqrWlXk",
        "outputId": "6812d1a7-4ce1-41b9-9916-f97ec83eb0dc"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-192-90dceb64b43d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Calcul et affichage de la matrice de confusion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmatrice_confusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred_lenet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Matrice de Confusion:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmatrice_confusion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_pred_lenet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher un compte-rendu évaluatif détaillé de la perfomance du modèle lenet à l'aide de la fonction classification_report du sous-module metrics de scikit-learn.\n",
        "\n",
        "print(metrics.classification_report(y_test_class, test_pred_lenet_class))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "tqHQMe4xWlZ8",
        "outputId": "4ae71a81-81a2-4189-8617-3dc6f1c17571"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-193-c0524c8fa73e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Afficher un compte-rendu évaluatif détaillé de la perfomance du modèle lenet à l'aide de la fonction classification_report du sous-module metrics de scikit-learn.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred_lenet_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "interprétation des résultats\n",
        "\n",
        "On remarque que la majorité des images sont bien identifiées et bien classées.\n",
        "Avec un taux de précision dépassant les .....% pour quelques minutes d'entraînement, on peut affirmer que ce modèle a rempli son objectif. \n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rA5z9GBlWlck",
        "outputId": "cf3cda97-8fee-4f60-92f5-54494dff92ed"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ninterprétation des résultats\\n\\nOn remarque que la majorité des images sont bien identifiées et bien classées.\\nAvec un taux de précision dépassant les .....% pour quelques minutes d'entraînement, on peut affirmer que ce modèle a rempli son objectif. \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    }
  ]
}
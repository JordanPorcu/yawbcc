{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f014c0e8",
   "metadata": {},
   "source": [
    "# Utilisation d'un réseau pré-entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e6fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append module location to sys.path\n",
    "import sys, pathlib, os\n",
    "pkg_path = pathlib.Path().cwd().parent\n",
    "sys.path.append(pkg_path.as_posix())\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2297d",
   "metadata": {},
   "source": [
    "## 1. Chargement du modèle VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7983a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.utils.image_dataset import image_dataset_from_directory, dataset_utils, ALLOWLIST_FORMATS\n",
    "\n",
    "from yawbcc.datasets import load_barcelona_wbc\n",
    "\n",
    "# Constants\n",
    "DATA_DIR = pathlib.Path.home() / 'yawbcc_data'\n",
    "INPUT_SHAPE = (256, 256, 3)\n",
    "NUM_CLASSES = 8\n",
    "\n",
    "# Load metadata\n",
    "meta = load_barcelona_wbc()\n",
    "\n",
    "# Create VGG16 model\n",
    "vgg16 = VGG16(weights='imagenet', input_shape=INPUT_SHAPE, include_top=False, pooling='avg')\n",
    "vgg16.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cb0eb6",
   "metadata": {},
   "source": [
    "## 2. Création du dataset à 8 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "844baac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17092 files belonging to 8 classes.\n",
      "Using 13674 files for training.\n",
      "Using 3418 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, valid_ds = image_dataset_from_directory(DATA_DIR / 'barcelona', validation_split=0.2, \n",
    "                                                  image_size=INPUT_SHAPE[:2], crop_to_aspect_ratio=True,\n",
    "                                                  subset='both', batch_size=32, shuffle=True, seed=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f70536e",
   "metadata": {},
   "source": [
    "## 3. Couche finale\n",
    "\n",
    "La couche finale est directement copiée de [l'implémentation de VGG16 par Keras](https://github.com/keras-team/keras-applications/blob/06fbeb0f16e1304f239b2296578d1c50b15a983a/keras_applications/vgg16.py#L176-L180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff580c47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"WBC\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 512)               14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 32)                16416     \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 32)                1056      \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,732,424\n",
      "Trainable params: 17,736\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Custom input block\n",
    "inputs = Input(shape=INPUT_SHAPE)\n",
    "x = vgg16(inputs, training=False)\n",
    "\n",
    "# Classification block\n",
    "x = Flatten(name='flatten')(x)  # Useless for polling='avg' or 'max' when instantiate VGG16\n",
    "x = Dense(32, activation='relu', name='fc1')(x)\n",
    "x = Dense(32, activation='relu', name='fc2')(x)\n",
    "x = Dense(NUM_CLASSES, activation='softmax', name='predictions')(x)\n",
    "\n",
    "# Create wbc classifier\n",
    "wbc = Model(inputs, x, name='WBC')\n",
    "wbc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671af4c",
   "metadata": {},
   "source": [
    "## 4. Entraînement\n",
    "\n",
    "L'entrainement a été réalisé sur une autre machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a4183bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "428/428 [==============================] - 187s 420ms/step - loss: 1.3933 - accuracy: 0.5335 - val_loss: 0.7613 - val_accuracy: 0.7303\n",
      "Epoch 2/20\n",
      "428/428 [==============================] - 174s 406ms/step - loss: 0.6730 - accuracy: 0.7704 - val_loss: 0.5873 - val_accuracy: 0.7984\n",
      "Epoch 3/20\n",
      "428/428 [==============================] - 175s 409ms/step - loss: 0.5708 - accuracy: 0.8026 - val_loss: 0.6092 - val_accuracy: 0.7908\n",
      "Epoch 4/20\n",
      "428/428 [==============================] - 177s 413ms/step - loss: 0.4993 - accuracy: 0.8300 - val_loss: 0.5063 - val_accuracy: 0.8259\n",
      "Epoch 5/20\n",
      "428/428 [==============================] - 177s 414ms/step - loss: 0.4377 - accuracy: 0.8502 - val_loss: 0.4609 - val_accuracy: 0.8464\n",
      "Epoch 6/20\n",
      "428/428 [==============================] - 176s 412ms/step - loss: 0.4296 - accuracy: 0.8504 - val_loss: 0.4590 - val_accuracy: 0.8394\n",
      "Epoch 7/20\n",
      "428/428 [==============================] - 178s 417ms/step - loss: 0.4091 - accuracy: 0.8572 - val_loss: 0.4665 - val_accuracy: 0.8455\n",
      "Epoch 8/20\n",
      "428/428 [==============================] - 177s 414ms/step - loss: 0.3943 - accuracy: 0.8656 - val_loss: 0.4784 - val_accuracy: 0.8394\n",
      "Epoch 9/20\n",
      "428/428 [==============================] - 178s 416ms/step - loss: 0.3711 - accuracy: 0.8717 - val_loss: 0.4513 - val_accuracy: 0.8514\n",
      "Epoch 10/20\n",
      "428/428 [==============================] - 178s 417ms/step - loss: 0.3546 - accuracy: 0.8772 - val_loss: 0.4408 - val_accuracy: 0.8496\n",
      "Epoch 11/20\n",
      "428/428 [==============================] - 177s 415ms/step - loss: 0.3461 - accuracy: 0.8780 - val_loss: 0.4119 - val_accuracy: 0.8642\n",
      "Epoch 12/20\n",
      "428/428 [==============================] - 177s 414ms/step - loss: 0.3355 - accuracy: 0.8836 - val_loss: 0.4106 - val_accuracy: 0.8634\n",
      "Epoch 13/20\n",
      "428/428 [==============================] - 180s 421ms/step - loss: 0.3284 - accuracy: 0.8836 - val_loss: 0.4542 - val_accuracy: 0.8537\n",
      "Epoch 14/20\n",
      "428/428 [==============================] - 176s 412ms/step - loss: 0.3257 - accuracy: 0.8864 - val_loss: 0.4585 - val_accuracy: 0.8537\n",
      "Epoch 15/20\n",
      "428/428 [==============================] - 176s 411ms/step - loss: 0.3133 - accuracy: 0.8913 - val_loss: 0.4434 - val_accuracy: 0.8572\n",
      "Epoch 16/20\n",
      "428/428 [==============================] - 176s 412ms/step - loss: 0.3162 - accuracy: 0.8885 - val_loss: 0.4622 - val_accuracy: 0.8452\n",
      "Epoch 17/20\n",
      "428/428 [==============================] - 175s 410ms/step - loss: 0.3057 - accuracy: 0.8951 - val_loss: 0.4739 - val_accuracy: 0.8432\n",
      "Epoch 18/20\n",
      "428/428 [==============================] - 176s 412ms/step - loss: 0.2993 - accuracy: 0.8949 - val_loss: 0.4502 - val_accuracy: 0.8569\n",
      "Epoch 19/20\n",
      "428/428 [==============================] - 179s 418ms/step - loss: 0.2918 - accuracy: 0.8967 - val_loss: 0.5187 - val_accuracy: 0.8370\n",
      "Epoch 20/20\n",
      "428/428 [==============================] - 175s 410ms/step - loss: 0.2928 - accuracy: 0.8973 - val_loss: 0.4313 - val_accuracy: 0.8622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff89fac5c70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbc.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "wbc.fit(train_ds, epochs=20, validation_data=valid_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
